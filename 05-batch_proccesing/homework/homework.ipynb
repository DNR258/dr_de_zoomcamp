{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23758d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a89f059a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/03 19:05:22 WARN Utils: Your hostname, LAPTOP-L2KUM3OT resolves to a loopback address: 127.0.1.1; using 172.29.152.43 instead (on interface eth0)\n",
      "24/03/03 19:05:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/03 19:05:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"test\") \\\n",
    "     .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f46edcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-01 19:44:26--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz\n",
      "Resolving github.com (github.com)... 20.201.28.151\n",
      "Connecting to github.com (github.com)|20.201.28.151|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240301%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240301T224427Z&X-Amz-Expires=300&X-Amz-Signature=a5a5147d8fb74c704763d0a9a643969072628143509303afa5f546ead229eab3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-03-01 19:44:27--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240301%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240301T224427Z&X-Amz-Expires=300&X-Amz-Signature=a5a5147d8fb74c704763d0a9a643969072628143509303afa5f546ead229eab3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19375751 (18M) [application/octet-stream]\n",
      "Saving to: ‘fhv_tripdata_2019-10.csv.gz’\n",
      "\n",
      "fhv_tripdata_2019-1 100%[===================>]  18.48M  3.48MB/s    in 5.5s    \n",
      "\n",
      "2024-03-01 19:44:33 (3.38 MB/s) - ‘fhv_tripdata_2019-10.csv.gz’ saved [19375751/19375751]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "147634d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gzip: fhv_tripdata_2019-10.csv already exists; do you wish to overwrite (y or n)? ^C\n"
     ]
    }
   ],
   "source": [
    "!gzip -d fhv_tripdata_2019-10.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16cdb72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1897494 fhv_tripdata_2019-10.csv\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l fhv_tripdata_2019-10.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ade7690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(\"fhv_tripdata_2019-10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b112c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropOff_datetime', StringType(), True), StructField('PUlocationID', StringType(), True), StructField('DOlocationID', StringType(), True), StructField('SR_Flag', StringType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49245577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B00009|2019-10-01 00:23:00|2019-10-01 00:35:00|         264|         264|   null|                B00009|\n",
      "|              B00013|2019-10-01 00:11:29|2019-10-01 00:13:22|         264|         264|   null|                B00013|\n",
      "|              B00014|2019-10-01 00:11:43|2019-10-01 00:37:20|         264|         264|   null|                B00014|\n",
      "|              B00014|2019-10-01 00:56:29|2019-10-01 00:57:47|         264|         264|   null|                B00014|\n",
      "|              B00014|2019-10-01 00:23:09|2019-10-01 00:28:27|         264|         264|   null|                B00014|\n",
      "|     B00021         |2019-10-01 00:00:48|2019-10-01 00:07:12|         129|         129|   null|       B00021         |\n",
      "|     B00021         |2019-10-01 00:47:23|2019-10-01 00:53:25|          57|          57|   null|       B00021         |\n",
      "|     B00021         |2019-10-01 00:10:06|2019-10-01 00:19:50|         173|         173|   null|       B00021         |\n",
      "|     B00021         |2019-10-01 00:51:37|2019-10-01 01:06:14|         226|         226|   null|       B00021         |\n",
      "|     B00021         |2019-10-01 00:28:23|2019-10-01 00:34:33|          56|          56|   null|       B00021         |\n",
      "|     B00021         |2019-10-01 00:31:17|2019-10-01 00:51:52|          82|          82|   null|       B00021         |\n",
      "|              B00037|2019-10-01 00:07:41|2019-10-01 00:15:23|         264|          71|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:13:38|2019-10-01 00:25:51|         264|          39|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:42:40|2019-10-01 00:53:47|         264|         188|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:58:46|2019-10-01 01:10:11|         264|          91|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:09:49|2019-10-01 00:14:37|         264|          71|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:22:35|2019-10-01 00:36:53|         264|          35|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:54:27|2019-10-01 01:03:37|         264|          61|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:08:12|2019-10-01 00:28:47|         264|         198|   null|                B00037|\n",
      "|              B00053|2019-10-01 00:05:24|2019-10-01 00:53:03|         264|         264|   null|                  #N/A|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b02768",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 101 fhv_tripdata_2019-10.csv > head.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f375e255",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l head.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f31e71b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e97d221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = pd.read_csv(\"head.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6295b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dispatching_base_num       object\n",
       "pickup_datetime            object\n",
       "dropOff_datetime           object\n",
       "PUlocationID                int64\n",
       "DOlocationID                int64\n",
       "SR_Flag                   float64\n",
       "Affiliated_base_number     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "801ba445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropOff_datetime', StringType(), True), StructField('PUlocationID', LongType(), True), StructField('DOlocationID', LongType(), True), StructField('SR_Flag', DoubleType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(df_pandas).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79e02b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39cd3be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True), \n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True), \n",
    "    types.StructField('dropOff_datetime', types.TimestampType(), True), \n",
    "    types.StructField('PUlocationID', types.IntegerType(), True), \n",
    "    types.StructField('DOlocationID', types.IntegerType(), True), \n",
    "    types.StructField('SR_Flag', types.StringType(), True), \n",
    "    types.StructField('Affiliated_base_number', types.StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aa87e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv(\"fhv_tripdata_2019-10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52e9feee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(dispatching_base_num='B00009', pickup_datetime=datetime.datetime(2019, 10, 1, 0, 23), dropOff_datetime=datetime.datetime(2019, 10, 1, 0, 35), PUlocationID=264, DOlocationID=264, SR_Flag=None, Affiliated_base_number='B00009')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230687c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672b9015",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet(\"fhv/2019/10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac68263d",
   "metadata": {},
   "source": [
    "# QUESTION 2: average size of Parquet files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a2659a56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 37M\r\n",
      "-rw-r--r-- 1 drios drios    0 Feb 28 01:52 _SUCCESS\r\n",
      "-rw-r--r-- 1 drios drios 6.2M Feb 28 01:52 part-00000-a1dc68cc-d281-42e8-8ed6-62ae7afd81ba-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 drios drios 6.2M Feb 28 01:52 part-00001-a1dc68cc-d281-42e8-8ed6-62ae7afd81ba-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 drios drios 6.2M Feb 28 01:52 part-00002-a1dc68cc-d281-42e8-8ed6-62ae7afd81ba-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 drios drios 6.2M Feb 28 01:52 part-00003-a1dc68cc-d281-42e8-8ed6-62ae7afd81ba-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 drios drios 6.2M Feb 28 01:52 part-00004-a1dc68cc-d281-42e8-8ed6-62ae7afd81ba-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 drios drios 6.2M Feb 28 01:52 part-00005-a1dc68cc-d281-42e8-8ed6-62ae7afd81ba-c000.snappy.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh fhv/2019/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "381a22f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"fhv/2019/10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "185e93c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[dispatching_base_num: string, pickup_datetime: timestamp, dropOff_datetime: timestamp, PUlocationID: int, DOlocationID: int, SR_Flag: string, Affiliated_base_number: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7fee8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: integer (nullable = true)\n",
      " |-- DOlocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e012a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[pickup_datetime: timestamp, dropOff_datetime: timestamp, PUlocationID: int, DOlocationID: int]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('pickup_datetime', 'dropOff_datetime', 'PUlocationID', 'DOlocationID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a88843b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[pickup_datetime: timestamp, dropOff_datetime: timestamp, PUlocationID: int, DOlocationID: int]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('pickup_datetime', 'dropOff_datetime', 'PUlocationID', 'DOlocationID') \\\n",
    "    .filter(df.dispatching_base_num == 'B00021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a860e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------------+------------+\n",
      "|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "|2019-10-03 09:38:00|2019-10-03 10:12:00|         264|         264|\n",
      "|2019-10-01 17:05:00|2019-10-01 17:49:00|         264|         264|\n",
      "|2019-10-03 09:48:00|2019-10-03 09:55:00|         264|         264|\n",
      "|2019-10-01 14:28:00|2019-10-01 14:42:00|         264|         264|\n",
      "|2019-10-07 21:50:00|2019-10-07 21:57:00|         264|         264|\n",
      "|2019-10-03 06:08:00|2019-10-03 06:35:00|         264|         264|\n",
      "|2019-10-03 21:31:00|2019-10-03 21:44:00|         264|         264|\n",
      "|2019-10-02 12:54:00|2019-10-02 13:04:00|         264|         264|\n",
      "|2019-10-08 16:21:00|2019-10-08 16:39:00|         264|         264|\n",
      "|2019-10-02 15:23:00|2019-10-02 15:33:00|         264|         264|\n",
      "|2019-10-08 11:00:00|2019-10-08 11:14:00|         264|         264|\n",
      "|2019-10-07 07:55:00|2019-10-07 08:03:00|         264|         264|\n",
      "|2019-10-08 11:23:00|2019-10-08 11:33:00|         264|         264|\n",
      "|2019-10-08 10:50:00|2019-10-08 11:04:00|         264|         264|\n",
      "|2019-10-03 05:28:00|2019-10-03 05:43:00|         264|         264|\n",
      "|2019-10-08 14:33:00|2019-10-08 14:50:00|         264|         264|\n",
      "|2019-10-04 16:36:00|2019-10-04 16:56:00|         264|         264|\n",
      "|2019-10-01 22:24:00|2019-10-01 22:39:00|         264|         264|\n",
      "|2019-10-04 23:06:00|2019-10-04 23:12:00|         264|         264|\n",
      "|2019-10-05 19:31:00|2019-10-05 19:45:00|         264|         264|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# no me reconoce B00021 xq tiene espacios, deberia meter algo similar a un TRIM\n",
    "df.select('pickup_datetime', 'dropOff_datetime', 'PUlocationID', 'DOlocationID') \\\n",
    "   .filter(df.dispatching_base_num == 'B00009') \\\n",
    "   .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f74d3be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dda0f70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-----------+------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|pickup_date|dropoff_date|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-----------+------------+\n",
      "|              B01239|2019-10-05 06:46:45|2019-10-05 07:02:22|         264|         259|   null|                B02883| 2019-10-05|  2019-10-05|\n",
      "|              B01338|2019-10-05 06:43:45|2019-10-05 06:51:27|         264|          18|   null|                B01338| 2019-10-05|  2019-10-05|\n",
      "|              B02133|2019-10-04 06:13:33|2019-10-04 07:27:47|         264|         264|   null|                B02870| 2019-10-04|  2019-10-04|\n",
      "|              B01751|2019-10-01 10:40:39|2019-10-01 10:44:42|         264|         264|   null|                B01751| 2019-10-01|  2019-10-01|\n",
      "|             B01629 |2019-10-08 14:11:36|2019-10-08 14:50:15|          80|          76|   null|               B01629 | 2019-10-08|  2019-10-08|\n",
      "|              B01087|2019-10-05 16:33:28|2019-10-05 18:23:48|         230|         265|   null|                B01087| 2019-10-05|  2019-10-05|\n",
      "|              B00837|2019-10-02 09:53:55|2019-10-02 15:41:51|         264|         264|   null|                B00837| 2019-10-02|  2019-10-02|\n",
      "|              B01145|2019-10-03 18:00:00|2019-10-03 18:09:09|         264|         167|   null|                B02867| 2019-10-03|  2019-10-03|\n",
      "|              B00310|2019-10-03 06:53:25|2019-10-03 07:08:03|         264|          47|   null|                B02917| 2019-10-03|  2019-10-03|\n",
      "|              B00037|2019-10-02 10:44:58|2019-10-02 10:49:43|         264|          62|   null|                B00037| 2019-10-02|  2019-10-02|\n",
      "|              B02096|2019-10-01 21:06:43|2019-10-01 21:35:11|         264|         159|   null|                B02096| 2019-10-01|  2019-10-01|\n",
      "|              B00937|2019-10-07 13:06:14|2019-10-07 13:21:42|         264|         243|   null|                B00937| 2019-10-07|  2019-10-07|\n",
      "|              B03160|2019-10-01 15:53:00|2019-10-01 16:26:00|          93|          93|   null|                B02788| 2019-10-01|  2019-10-01|\n",
      "|              B01445|2019-10-05 18:53:00|2019-10-05 19:25:00|          14|         228|   null|                B01445| 2019-10-05|  2019-10-05|\n",
      "|              B02735|2019-10-02 19:11:39|2019-10-02 19:39:22|         264|         159|   null|                B02932| 2019-10-02|  2019-10-02|\n",
      "|              B03016|2019-10-04 12:33:52|2019-10-04 12:45:16|         264|         254|   null|                B02876| 2019-10-04|  2019-10-04|\n",
      "|              B01808|2019-10-04 15:00:00|2019-10-04 15:12:00|         264|         264|   null|                B01808| 2019-10-04|  2019-10-04|\n",
      "|              B02401|2019-10-03 06:59:38|2019-10-03 07:34:08|         264|         132|   null|                B02401| 2019-10-03|  2019-10-03|\n",
      "|              B00014|2019-10-01 18:19:40|2019-10-01 18:32:45|         264|         264|   null|                B00014| 2019-10-01|  2019-10-01|\n",
      "|              B00937|2019-10-01 06:33:06|2019-10-01 07:03:16|         264|         138|   null|                B00937| 2019-10-01|  2019-10-01|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "  .withColumn('dropoff_date', F.to_date(df.dropOff_datetime)) \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f75fe3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 11:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+------------+------------+\n",
      "|pickup_date|dropoff_date|PUlocationID|DOlocationID|\n",
      "+-----------+------------+------------+------------+\n",
      "| 2019-10-05|  2019-10-05|         264|         259|\n",
      "| 2019-10-05|  2019-10-05|         264|          18|\n",
      "| 2019-10-04|  2019-10-04|         264|         264|\n",
      "| 2019-10-01|  2019-10-01|         264|         264|\n",
      "| 2019-10-08|  2019-10-08|          80|          76|\n",
      "| 2019-10-05|  2019-10-05|         230|         265|\n",
      "| 2019-10-02|  2019-10-02|         264|         264|\n",
      "| 2019-10-03|  2019-10-03|         264|         167|\n",
      "| 2019-10-03|  2019-10-03|         264|          47|\n",
      "| 2019-10-02|  2019-10-02|         264|          62|\n",
      "| 2019-10-01|  2019-10-01|         264|         159|\n",
      "| 2019-10-07|  2019-10-07|         264|         243|\n",
      "| 2019-10-01|  2019-10-01|          93|          93|\n",
      "| 2019-10-05|  2019-10-05|          14|         228|\n",
      "| 2019-10-02|  2019-10-02|         264|         159|\n",
      "| 2019-10-04|  2019-10-04|         264|         254|\n",
      "| 2019-10-04|  2019-10-04|         264|         264|\n",
      "| 2019-10-03|  2019-10-03|         264|         132|\n",
      "| 2019-10-01|  2019-10-01|         264|         264|\n",
      "| 2019-10-01|  2019-10-01|         264|         138|\n",
      "+-----------+------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "  .withColumn('dropoff_date', F.to_date(df.dropOff_datetime)) \\\n",
    "  .select('pickup_date', 'dropoff_date', 'PUlocationID', 'DOlocationID') \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4093da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crazy_stuff(base_num):\n",
    "    num = int(base_num[1:])\n",
    "    if num % 7 == 0:\n",
    "        return f's/{num:03x}'\n",
    "    elif num % 3 == 0:\n",
    "        return f'a/{num:03x}'\n",
    "    else:\n",
    "        return f'e/{num:03x}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e34bd0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "crazy_stuff_udf = F.udf(crazy_stuff, returnType=types.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e620403e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a/009'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crazy_stuff('B00009')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d87f3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+-----------+------------+------------+------------+\n",
      "|dispatching_base_num|coded_id|pickup_date|dropoff_date|PUlocationID|DOlocationID|\n",
      "+--------------------+--------+-----------+------------+------------+------------+\n",
      "|              B01239|   s/4d7| 2019-10-05|  2019-10-05|         264|         259|\n",
      "|              B01338|   a/53a| 2019-10-05|  2019-10-05|         264|          18|\n",
      "|              B02133|   a/855| 2019-10-04|  2019-10-04|         264|         264|\n",
      "|              B01751|   e/6d7| 2019-10-01|  2019-10-01|         264|         264|\n",
      "|             B01629 |   a/65d| 2019-10-08|  2019-10-08|          80|          76|\n",
      "|              B01087|   e/43f| 2019-10-05|  2019-10-05|         230|         265|\n",
      "|              B00837|   a/345| 2019-10-02|  2019-10-02|         264|         264|\n",
      "|              B01145|   e/479| 2019-10-03|  2019-10-03|         264|         167|\n",
      "|              B00310|   e/136| 2019-10-03|  2019-10-03|         264|          47|\n",
      "|              B00037|   e/025| 2019-10-02|  2019-10-02|         264|          62|\n",
      "|              B02096|   e/830| 2019-10-01|  2019-10-01|         264|         159|\n",
      "|              B00937|   e/3a9| 2019-10-07|  2019-10-07|         264|         243|\n",
      "|              B03160|   e/c58| 2019-10-01|  2019-10-01|          93|          93|\n",
      "|              B01445|   e/5a5| 2019-10-05|  2019-10-05|          14|         228|\n",
      "|              B02735|   e/aaf| 2019-10-02|  2019-10-02|         264|         159|\n",
      "|              B03016|   e/bc8| 2019-10-04|  2019-10-04|         264|         254|\n",
      "|              B01808|   e/710| 2019-10-04|  2019-10-04|         264|         264|\n",
      "|              B02401|   s/961| 2019-10-03|  2019-10-03|         264|         132|\n",
      "|              B00014|   s/00e| 2019-10-01|  2019-10-01|         264|         264|\n",
      "|              B00937|   e/3a9| 2019-10-01|  2019-10-01|         264|         138|\n",
      "+--------------------+--------+-----------+------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('coded_id', crazy_stuff_udf(df.dispatching_base_num)) \\\n",
    "  .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "  .withColumn('dropoff_date', F.to_date(df.dropOff_datetime)) \\\n",
    "  .select('dispatching_base_num', 'coded_id', 'pickup_date', 'dropoff_date', 'PUlocationID', 'DOlocationID') \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77a825e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOMEWORK SECOND PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55dcae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "529ff5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod = df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .withColumn('dropoff_date', F.to_date(df.dropOff_datetime)) \\\n",
    "    .select('dispatching_base_num', 'pickup_date', 'dropoff_date', 'PUlocationID', 'DOlocationID', 'pickup_datetime', 'dropOff_datetime') \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d84b1b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+------------+------------+------------+\n",
      "|dispatching_base_num|pickup_date|dropoff_date|PUlocationID|DOlocationID|\n",
      "+--------------------+-----------+------------+------------+------------+\n",
      "|              B01239| 2019-10-05|  2019-10-05|         264|         259|\n",
      "|              B01338| 2019-10-05|  2019-10-05|         264|          18|\n",
      "|              B02133| 2019-10-04|  2019-10-04|         264|         264|\n",
      "|              B01751| 2019-10-01|  2019-10-01|         264|         264|\n",
      "|             B01629 | 2019-10-08|  2019-10-08|          80|          76|\n",
      "|              B01087| 2019-10-05|  2019-10-05|         230|         265|\n",
      "|              B00837| 2019-10-02|  2019-10-02|         264|         264|\n",
      "|              B01145| 2019-10-03|  2019-10-03|         264|         167|\n",
      "|              B00310| 2019-10-03|  2019-10-03|         264|          47|\n",
      "|              B00037| 2019-10-02|  2019-10-02|         264|          62|\n",
      "|              B02096| 2019-10-01|  2019-10-01|         264|         159|\n",
      "|              B00937| 2019-10-07|  2019-10-07|         264|         243|\n",
      "|              B03160| 2019-10-01|  2019-10-01|          93|          93|\n",
      "|              B01445| 2019-10-05|  2019-10-05|          14|         228|\n",
      "|              B02735| 2019-10-02|  2019-10-02|         264|         159|\n",
      "|              B03016| 2019-10-04|  2019-10-04|         264|         254|\n",
      "|              B01808| 2019-10-04|  2019-10-04|         264|         264|\n",
      "|              B02401| 2019-10-03|  2019-10-03|         264|         132|\n",
      "|              B00014| 2019-10-01|  2019-10-01|         264|         264|\n",
      "|              B00937| 2019-10-01|  2019-10-01|         264|         138|\n",
      "+--------------------+-----------+------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_mod.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10f47576",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod.createOrReplaceTempView('df_query')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c175c66",
   "metadata": {},
   "source": [
    "# QUESTION 3: 2019-10-15 count records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "644b375a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:=================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|pickup_date|count(pickup_date)|\n",
      "+-----------+------------------+\n",
      "| 2019-10-15|             62610|\n",
      "+-----------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "SELECT \n",
    "    pickup_date,\n",
    "    COUNT(pickup_date)\n",
    "FROM df_query\n",
    "WHERE pickup_date = \"2019-10-15\"\n",
    "GROUP BY 1\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b301572",
   "metadata": {},
   "source": [
    "# QUESTION 4: longest trip in the dataset (in hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1980b0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:======================================>                   (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+------------------+\n",
      "|dispatching_base_num|pickup_date|             hours|\n",
      "+--------------------+-----------+------------------+\n",
      "|              B02832| 2019-10-11|          631152.5|\n",
      "|              B02832| 2019-10-28|          631152.5|\n",
      "|              B02416| 2019-10-31| 87672.43333333333|\n",
      "|     B00746         | 2019-10-01| 70128.01666666666|\n",
      "|              B02921| 2019-10-17|            8794.0|\n",
      "|              B03110| 2019-10-26| 8784.166666666666|\n",
      "|              B03080| 2019-10-30|1464.5333333333333|\n",
      "|     B03084         | 2019-10-25|1056.8166666666666|\n",
      "|     B03084         | 2019-10-25|1056.2666666666667|\n",
      "|              B01452| 2019-10-01|            793.55|\n",
      "|              B01452| 2019-10-01| 793.3833333333333|\n",
      "|              B01452| 2019-10-01| 793.2833333333333|\n",
      "|              B01452| 2019-10-01| 792.9833333333333|\n",
      "|              B01452| 2019-10-01| 792.9833333333333|\n",
      "|              B01452| 2019-10-01|            792.85|\n",
      "|              B01452| 2019-10-01|             792.8|\n",
      "|              B01452| 2019-10-01| 792.7833333333333|\n",
      "|              B00972| 2019-10-01| 792.7666666666667|\n",
      "|              B00972| 2019-10-01|            792.75|\n",
      "|              B01452| 2019-10-01| 792.7333333333333|\n",
      "+--------------------+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "SELECT\n",
    "    dispatching_base_num, \n",
    "    pickup_date,\n",
    "    (diff / 60) AS hours\n",
    "FROM \n",
    "    (SELECT \n",
    "       dispatching_base_num, \n",
    "       pickup_date,\n",
    "       TIMESTAMPDIFF(MINUTE, pickup_datetime, dropOff_datetime) AS diff\n",
    "     FROM df_query) AS subq\n",
    "ORDER BY diff DESC\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "95fe77a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+------------+------------+------------+-------------------+-------------------+\n",
      "|dispatching_base_num|pickup_date|dropoff_date|PUlocationID|DOlocationID|    pickup_datetime|   dropOff_datetime|\n",
      "+--------------------+-----------+------------+------------+------------+-------------------+-------------------+\n",
      "|              B01239| 2019-10-05|  2019-10-05|         264|         259|2019-10-05 06:46:45|2019-10-05 07:02:22|\n",
      "|              B01338| 2019-10-05|  2019-10-05|         264|          18|2019-10-05 06:43:45|2019-10-05 06:51:27|\n",
      "|              B02133| 2019-10-04|  2019-10-04|         264|         264|2019-10-04 06:13:33|2019-10-04 07:27:47|\n",
      "|              B01751| 2019-10-01|  2019-10-01|         264|         264|2019-10-01 10:40:39|2019-10-01 10:44:42|\n",
      "|             B01629 | 2019-10-08|  2019-10-08|          80|          76|2019-10-08 14:11:36|2019-10-08 14:50:15|\n",
      "|              B01087| 2019-10-05|  2019-10-05|         230|         265|2019-10-05 16:33:28|2019-10-05 18:23:48|\n",
      "|              B00837| 2019-10-02|  2019-10-02|         264|         264|2019-10-02 09:53:55|2019-10-02 15:41:51|\n",
      "|              B01145| 2019-10-03|  2019-10-03|         264|         167|2019-10-03 18:00:00|2019-10-03 18:09:09|\n",
      "|              B00310| 2019-10-03|  2019-10-03|         264|          47|2019-10-03 06:53:25|2019-10-03 07:08:03|\n",
      "|              B00037| 2019-10-02|  2019-10-02|         264|          62|2019-10-02 10:44:58|2019-10-02 10:49:43|\n",
      "+--------------------+-----------+------------+------------+------------+-------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 45:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "SELECT \n",
    "   *\n",
    "FROM df_query\n",
    "LIMIT 10\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "54661afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READING ZONES\n",
    "df_zones = spark.read.option('header', 'true').csv(\"zones_csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "042328a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|locationid|      borough|                zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3eaa5c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- locationid: string (nullable = true)\n",
      " |-- borough: string (nullable = true)\n",
      " |-- zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "93c55489",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "421f211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones_schema = types.StructType([\n",
    "    types.StructField('locationid', types.IntegerType(), True), \n",
    "    types.StructField('borough', types.StringType(), True), \n",
    "    types.StructField('zone', types.StringType(), True), \n",
    "    types.StructField('service_zone', types.StringType(), True), \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "951e5abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read.option('header', 'true').schema(zones_schema).csv(\"zones_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fe7ad073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|locationid|      borough|                zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "26845a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- locationid: integer (nullable = true)\n",
      " |-- borough: string (nullable = true)\n",
      " |-- zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bd053455",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones.write.parquet(\"zones_format_pq/2019/10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4d52f83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_format = spark.read.parquet(\"zones_format_pq/2019/10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d5064584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- locationid: integer (nullable = true)\n",
      " |-- borough: string (nullable = true)\n",
      " |-- zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_format.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2c0fc81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|locationid|      borough|                zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_format.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bb6a8513",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_format.createOrReplaceTempView('df_qzones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c2a825b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+----+------------+\n",
      "|locationid|borough|zone|service_zone|\n",
      "+----------+-------+----+------------+\n",
      "|       264|Unknown|  NV|         N/A|\n",
      "+----------+-------+----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "SELECT \n",
    "    *\n",
    "FROM df_qzones\n",
    "WHERE zone = 'NV'\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73293b05",
   "metadata": {},
   "source": [
    "# QUESTION 6: Least frequent pickup location zone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b075fbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 83:======================================>                   (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|       zone|abs_freq|\n",
      "+-----------+--------+\n",
      "|Jamaica Bay|       1|\n",
      "+-----------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "SELECT \n",
    "    pu.zone,\n",
    "    COUNT(ma.PUlocationID) AS abs_freq\n",
    "FROM \n",
    "    df_query AS ma\n",
    "INNER JOIN \n",
    "    df_qzones AS pu\n",
    "ON ma.PUlocationID = pu.locationid\n",
    "WHERE pu.borough != 'Unknown'\n",
    "GROUP BY zone\n",
    "ORDER BY abs_freq ASC\n",
    "LIMIT 1\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af8c87e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
